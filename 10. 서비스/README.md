###################################################################
토픽1. 데이터 - 캐시

캐시를 구현한다면 어떻게 구현하겠는가? 단 데이터를 최대 n개 저장할 수 있고, 캐시가 꽉 차면 LRU 방식으로 기존 데이터 제거, 새 데이터를 추가할 수 있어야 한다고 가정하라
 
Local Cache vs Global Cache 
저장 위치의 차이로 인해, Local Cache와 Global Cache는 다양한 상황에서 성능적 차이를 보입니다. Local Cache와 Global Cache의 특징을 각각 알아보겠습니다.
 
Local Cache의 특징 
데이터 조회 오버헤드가 없다. 캐시 데이터를 서버 메모리상에 두는 것의 가장 큰 장점은, 무엇보다도 속도가 빠르다는 점입니다. 캐시를 외부 저장소에 저장하면 네트워크 통신을 통해 캐시 저장소에 접근하고, 데이터를 가져오는 과정 등의 오버헤드가 없기 때문에 Local Cache의 데이터 읽기 속도는 현저히 빠릅니다.

그러나 서버 간 데이터 일관성이 깨질 수 있다. Local Cache는 단일 서버 인스턴스에 캐시 데이터를 저장하기 때문에, 서버의 인스턴스가 여러 개일 경우 서버 간 캐시 데이터가 일치하지 않아 신뢰성을 떨어뜨릴 수 있습니다. 서버간 동기화가 어렵고, 동기화 비용이 발생한다. 캐시 일관성을 유지하기 위해 동기화를 한다고 하더라도, 추가적인 비용이 발생합니다. 더군다나 서버의 개수가 늘어날수록, 자신을 제외한 모든 인스턴스와 동기화 작업을 해야 하기 때문에 비용의 크기는 서버의 개수의 제곱에 비례하여 증가합니다.
 
Global Cache의 특징
네트워크 I/O 비용 발생. Global Cache는 외부 캐시 저장소에 접근하여 데이터를 가져오기 때문에, 이 과정에서 네트워크 I/O가 비용이 발생합니다. 하지만 서버 인스턴스가 추가될 때에도 동일한 비용만을 요구하기 때문에, 서버가 고도화될수록 더 높은 효율을 발휘합니다.

데이터 일관성을 유지할 수 있다. Global Cache는 모든 서버의 인스턴스가 동일한 캐시 저장소에 접근하기 때문에, 데이터의 일관성을 보장할 수 있습니다. 데이터의 일관성이 깨지기 쉬운 분산 서버 환경에 적합한 구조입니다.
 
Local Cache와 Global Cache의 특성을 고려했을 때, 어떤 기술을 선택해야 할지에 대한 기준은 "데이터의 일관성이 깨져도 비즈니스에 영향을 주지 않는가?"라고 생각합니다.
 
Redis

자체적으로 클러스터링과 분산 캐시 및 페일오버가 구현되어 있어서, 글로벌 캐시 전략을 사용하기에 좋습니다. 데이터에 만료시간을 지정할 수 있어서 지정된 만료시간이 지나면 해당 데이터는 Redis에서 삭제되며, 만료되지 않았지만 메모리가 꽉 찼을때도 LRU(Least recently used) 알고리즘에 의해 데이터가 사라집니다. express 서버 속도도 빨라질 수 있겠군…
비어 있는 마스터 노드가 리플리케이션 되는 것을 주의해야 합니다. Redis는 RDB, AOF를 이용하여 스냅샷을 뜰수 있고, 장애대한 데이터 유실을 대비 할 수 있습니다. 마스터 노드는 속도를 위해 RDB, AOF를 사용하지 않고, 슬레이브 노드에서만 RDB, AOF를 사용하는데, 마스터 노드가 장애로 Shutdown 상태로 빠졌다가 Startup 된다면 해당 마스터 노드는 비어있는 상태로 올라오게 됩니다. 마스터가 비어있게 되면, 마스터를 기준으로 동기화하는 슬레이브도 역시 빈상태로 동기화가 진행됩니다.
현재 버전은 마스터 노드에 장애가 발생하면 해당 마스터에 종속된 슬레이브를 자동으로 마스터로 승격하고, 마스터가 복귀하면 동기화 후에 다시 슬레이브로 돌려 놓습니다. 장애난 마스터노드는 다시 클러스터에 들어왔을때 슬레이브 모드로 복구를 진행후에 다시 마스터로 돌려 놓습니다.
 Redis는 메모리 기반이기 때문에 장비에 Redis에 할당 할 수 있는 메모리가 많으면 좋습니다. 하지만 그만큼 메모리 할당에 있어 주의 해야합니다. 서버에 16GB의 메모리가 있다고 해서 Redis가 16GB를 모두 사용할 수가 없습니다. 기본적으로 OS가 사용하는 메모리 양이 있고, 모니터링이나 배치에서 사용하는 메모리가 있을수 있기 때문입니다. 일반적으로 전체 메모리의 60~70% 정도 사용하는 것이 안정적입니다. 갑자기 성능저하가 발생했다면 할당된 메모리를 넘어서 Swap을 사용하고 있는지 체크해봐야 합니다. Redis는 Memcached와 달리 RDB를 이용한 데이터 유실없이 재시작 할 수 있으므로 프로세서를 종료후 재시작하면 문제를 해결할 수 있습니다. 또는 OS상의 메모리 캐시를 전부 삭제하여 스왑을 제거할 수 있습니다.
###################################################################
대규모 데이터

###################################################################
## 토픽2. 트래픽
Q. 1억명의 유저에게 알림을 보내야 한다면 어떻게 해야 할까?
- 분산 서버
- msa docker kubernetes
###################################################################
트래픽 - 메시지 큐 Kafka

메시지 큐를 사용함으로써 얻을 수 있는 이점은 다음과 같다.
비동기(Asynchronous)
메시지 큐는 생산된 메시지의 저장, 전송에 대해 동기화 처리를 진행하지 않고, 큐에 넣어 두기 때문에 나중에 처리할 수 있다. 여기서, 기존 동기화 방식은 많은 메시지(데이터)가 전송될 경우 병목이 생길 수 있고, 뒤에 들어오는 요청에 대한 응답이 지연될 것이다.
낮은 결합도(Decoupling)
생산자 서비스와 소비자 서비스가 독립적으로 행동하게 됨으로써 서비스 간 결합도가 낮아진다.
확장성(Scalable)
생산자 서비스 혹은 소비자 서비스를 원하는 대로 확장할 수 있기 때문에 확장성이 좋다.
탄력성(Resilience)
소비자 서비스가 다운되더라도 어플리케이션이 중단되는 것은 아니다. 메시지는 메시지 큐에 남아 있다. 소비자 서비스가 다시 시작될 때마다 추가 설정이나 작업을 수행하지 않고도 메시지 처리를 시작할 수 있다.
보장성(Guarantees)
메시지 큐는 큐에 보관되는 모든 메시지가 결국 소비자 서비스에게 전달된다는 일반적인 보장을 제공한다.
###################################################################
토픽3. 네트워크 인터페이스 - gRPC, graphql

Socket
IPC 기법에는 공유 메모리, PIPE, 메시지 큐 등 여러가지가 있지만 이 중 소켓(socket)을 살펴보겠습니다. socket이란, 앞서 언급한 OSI 7 layer 구조의 Application Layer(L7)에서 Transport Port(L4)의 TCP 또는 UDP를 이용하기 위한 수단입니다. 일종의 창구 역할을 하는 것이죠. 목적지와의 통신이 컴퓨터 내부가 아니라 온라인 범위에서 이루어지기 때문에 네트워크 간 통신이라고 구분하기도 하지만, 실질적으로는 로컬 컴퓨터의 프로세스와 원격지 컴퓨터의 프로세스가 IPC 통신을 하는 것입니다.

소켓은 대부분의 언어에서 API 형태로 제공하는 편리함 때문에 지금도 많이 사용되고 있지만, 일련의 통신 과정을 직접 구현하므로 통신 관련 장애를 처리하는 것은 고스란히 개발자의 몫이 됩니다. 서비스가 고도화될 수록 수백 수천가지 데이터가 돌아다니게 될텐데, 이에 따라 data formatting 을 하는 것도 점점 어려워지게 되죠.

RPC (Remote Procedure Call)
이런 소켓의 한계에서 RPC(Remote Procedure Call)라는 기술이 등장합니다. 이름 그대로 네트워크로 연결된 서버 상의 함수를 원격으로 호출할 수 있는 기능입니다. 네트워크 통신을 위한 작업 하나하나 챙기기 귀찮으니. 통신이나 call 방식에 신경쓰지 않고 원격지의 자원을 내 것처럼 사용할 수 있죠. 다양한 언어를 가진 환경에서도 쉽게 확장이 가능하며, 인터페이스 협업에도 용이하다는 장점이 있습니다.
핵심 개념은 ‘Stub(스텁)’이라는 것인데요. 서버와 클라이언트는 서로 다른 주소 공간을 사용 하므로, 함수 호출에 사용된 매개 변수를 꼭 변환해줘야 합니다. 안그러면 메모리 매개 변수에 대한 포인터가 다른 데이터를 가리키게 될 테니까요. 이 변환을 담당하는게 스텁입니다.
client stub은 함수 호출에 사용된 파라미터의 변환 및 함수 실행 후 서버에서 전달 된 결과를 변환하고, server stub은 클라이언트가 전달한 매개 변수의 역변환 및 함수 실행 결과 변환을 담당하게 됩니다. 이런 Stub을 이용한 기본적인 RPC 통신 과정을 살펴보겠습니다.
① IDL(Interface Definition Language)을 사용하여 호출 규약 정의합니다.
- 함수명, 인자, 반환값에 대한 데이터형이 정의된 IDL 파일을 rpcgen으로 컴파일하면 stub code가 자동으로 생성됩니다.
② Stub Code에 명시된 함수는 원시코드의 형태로, 상세 기능은 server에서 구현됩니다.
- 만들어진 stub 코드는 클라이언트/서버에 함께 빌드합니다.
③ client에서 stub 에 정의된 함수를 사용할 때,
④ client stub은 RPC runtime을 통해 함수 호출하고
⑤ server는 수신된 procedure 호출에 대한 처리 후 결과 값을 반환합니다.
⑥ 최종적으로 Client는 Server의 결과 값을 반환받고, 함수를 Local에 있는 것 처럼 사용할 수 있습니다.
그러나 RPC 프로젝트도 점차 뒷길로 가게되며 데이터 통신을 우리에게 익숙한 Web을 활용해보려는 시도로 이어졌고, 이 자리를 REST가 차지하게됩니다.

REST (REpresentational State Transfer)
REST는 HTTP/1.1 기반으로 URI를 통해 모든 자원(Resource)을 명시하고 HTTP Method를 통해 처리하는 아키텍쳐 입니다. 하지만 REST에도 한계는 존재합니다. REST는 일종의 스타일이지 표준이 아니기 때문에 parameter와 응답 값이 명시적이지 않아요. 또한 HTTP 메소드의 형태가 제한적이기 때문에 세부 기능 구현에는 제약이 있습니다.
덧붙여, 웹 데이터 전달 format으로 xml, json을 많이 사용하는데요. XML은 복잡하고 비효율적인 데이터 구조탓에 속도가 느리다는 단점이 있었습니다. 이런 효율 문제를 JSON이 간결한 Key-Value 구조 기반으로 해결하는 듯 하였으나, 제공되는 자료형의 한계로 파싱 후 추가 형변환이 필요한 경우가 많아졌습니다. 또한 두 타입 모두 string 기반이라 사람이 읽기 편하다는 장점은 있으나, 바꿔 말하면 데이터 전송 및 처리를 위해선 별도의 Serialization이 필요하다는 것을 의미합니다.
쉽게 말해 REST API는 다음의 구성으로 이루어져 있다.

자원(RESOURCE) - URI
행위(Verb) - HTTP METHOD
표현(Representations)

 자원(RESOURCE)

모든 자원에 고유한 ID가 존재하고, 이 자원은 Server에 존재한다.
자원을 구별하는 ID는 /orders/order_id/1와 같은 HTTP URI이다.

 행위(Verb)

HTTP 프로토콜의 Method를 사용한다.
HTTP 프로토콜은 GET, POST, PUT, DELETE와 같은 메서드를 제공한다.

 표현 (Representation of Resource)

Client가 자원의 상태(정보)에 대한 조작을 요청하면 Server는 이에 적절한 응답(Representation)을 보낸다.
REST에서 하나의 자원은 JSON, XML, TEXT, RSS 등 여러 형태의 Representation으로 나타낼 수 있다.
현재는 JSON으로 주고 받는 것이 대부분이다.

1) Uniform (유니폼 인터페이스)
Uniform Interface는 URI로 지정한 리소스에 대한 조작을 통일되고 한정적인 인터페이스로 수행하는 아키텍처 스타일을 말한다.

2) Stateless (무상태성)
REST는 무상태성 성격을 갖는다. 다시 말해 작업을 위한 상태정보를 따로 저장하고 관리하지 않는다. 세션 정보나 쿠키정보를 별도로 저장하고 관리하지 않기 때문에 API 서버는 들어오는 요청만을 단순히 처리하면 된다. 때문에 서비스의 자유도가 높아지고 서버에서 불필요한 정보를 관리하지 않음으로써 구현이 단순해진다.

3) Cacheable (캐시 가능)
REST의 가장 큰 특징 중 하나는 HTTP라는 기존 웹표준을 그대로 사용하기 때문에, 웹에서 사용하는 기존 인프라를 그대로 활용이 가능하다. 따라서 HTTP가 가진 캐싱 기능이 적용 가능합니다. HTTP 프로토콜 표준에서 사용하는 Last-Modified 태그나 E-Tag를 이용하면 캐싱 구현이 가능하다.

4) Self-Descriptiveness (자체 표현 구조)
REST의 또 다른 특징 중 하나는 REST API 메시지만 보고도 이를 쉽게 이해 할 수 있는 자체 표현 구조로 되어 있는 것이다.

5) Client-Server 구조
REST 서버는 API 제공, 클라이언트는 사용자 인증이나 컨텍스트(세션, 로그인 정보)등을 직접 관리하는 구조로 각각의 역할이 확실히 구분되기 때문에 클라이언트와 서버에서 개발해야 할 내용이 명확해지고 서로간 의존성이 줄어들게 된다.

6) 계층형 구조
REST 서버는 다중 계층으로 구성될 수 있으며 보안, 로드 밸런싱, 암호화 계층을 추가해 구조상의 유연성을 둘 수 있고 PROXY, 게이트웨이 같은 네트워크 기반의 중간매체를 사용할 수 있게 합니다.

 REST API 디자인 가이드

REST API 설계 시 가장 중요한 항목은 다음의 2가지로 요약할 수 있다.
첫 번째, URI는 정보의 자원을 표현해야 한다.
두 번째, 자원에 대한 행위는 HTTP Method(GET, POST, PUT, DELETE)로 표현한다.
꼭 기억하기!!

 REST API 중심 규칙

1) URI는 정보의 자원을 표현해야 한다. (리소스명은 동사보다는 명사를 사용)
GET /members/delete/1


위와 같은 방식은 REST를 제대로 적용하지 않은 URI이다. URI는 자원을 표현하는데 중점을 두어야 한다. delete와 같은 행위에 대한 표현이 들어가서는 안된다.

2) 자원에 대한 행위는 HTTP Method(GET, POST, PUT, DELETE 등)로 표현
위의 잘못 된 URI를 HTTP Method를 통해 수정해 보자.
DELETE /members/1


으로 수정할 수 있다. 회원정보를 가져올 때는 GET, 회원 추가 시의 행위를 표현하고자 할 때는 POST METHOD를 사용하여 표현한다.

회원정보를 가져오는 URI
GET /members/show/1    (x)
GET /members/1         (o)


회원을 추가할 때
GET /members/insert/2    (x)   - GET 메서드는 리소스 생성에 맞지 않는다.
POST /members/2          (o)


3) 슬래시 구분자(/)는 계층 관계를 나타내는 데 사용
  http://restapi.example.com/houses/apartments
   http://restapi.example.com/animals/mammals/whales


4) URI 마지막 문자로 슬래시(/)를 포함하지 않는다.
URI에 포함되는 모든 글자는 리소스의 유일한 식별자로 사용되어야 하며 URI가 다르다는 것은 리소스가 다르다는 것이고, 역으로 리소스가 다르면 URI도 달라져야 한다. REST API는 분명한 URI를 만들어 통신을 해야 하기 때문에 혼동을 주지 않도록 URI 경로의 마지막에는 슬래시(/)를 사용하지 않는다.
   http://restapi.example.com/houses/apartments/ (X)
    http://restapi.example.com/houses/apartments  (0)


5) 하이픈(-)은 URI 가독성을 높이는데 사용
URI를 쉽게 읽고 해석하기 위해, 불가피하게 긴 URI 경로를 사용하게 된다면 하이픈을 사용해 가독성을 높일 수 있다.

6) 밑줄(_)은 URI에 사용하지 않는다.
글꼴에 따라 다르긴 하지만 밑줄은 보기 어렵거나 밑줄 때문에 문자가 가려지기도 한다. 이런 문제를 피하기 위해 밑줄 대신 하이픈(-)을 사용하는 것이 좋다.(가독성)

7) URI 경로에는 소문자가 적합하다.
URI 경로에 대문자 사용은 피하도록 해야 합니다. 대소문자에 따라 다른 리소스로 인식하게 되기 때문입니다. RFC 3986(URI 문법 형식)은 URI 스키마와 호스트를 제외하고는 대소문자를 구별하도록 규정하기 때문이지요.

8) 파일 확장자는 URI에 포함시키지 않는다.
   http://restapi.example.com/members/soccer/345/photo.jpg (X)


8) 리소스 간의 관계 표현 방법
REST 리소스 간에는 연관 관계가 있을 수 있고, 이런 경우 다음과 같은 표현방법으로 사용한다.
/리소스명/리소스 ID/관계가 있는 다른 리소스명

ex)    GET : /users/{userid}/devices (일반적으로 소유 ‘has’의 관계를 표현할 때)


만약에 관계명이 복잡하다면 이를 서브 리소스에 명시적으로 표현하는 방법이 있다. 예를 들어 사용자가 ‘좋아하는’ 디바이스 목록을 표현해야 할 경우 다음과 같은 형태로 사용될 수 있다.
GET : /users/{userid}/likes/devices (관계명이 애매하거나 구체적 표현이 필요할 때)


 REST의 장점

HTTP 프로토콜의 인프라를 그대로 사용하므로 REST API 사용을 위한 별도의 인프라를 구축할 필요가 없다.
HTTP 프로토콜의 표준을 최대한 활용하여 여러 추가적인 장점을 함께 가져갈 수 있게 해준다.
HTTP 표준 프로토콜에 따르는 모든 플랫폼에서 사용이 가능하다.
Hypermedia API의 기본을 충실히 지키면서 범용성을 보장한다.
REST API 메시지가 의도하는 바를 명확하게 나타내므로 의도하는 바를 쉽게 파악할 수 있다.
여러 가지 서비스 디자인에서 생길 수 있는 문제를 최소화한다.
서버와 클라이언트의 역할을 명확하게 분리한다.

 REST의 단점

표준이 존재하지 않아 정의가 필요하다
사용할 수 있는 메소드가 4가지 밖에 없다.
HTTP Method 형태가 제한적이다.
브라우저를 통해 테스트할 일이 많은 서비스라면 쉽게 고칠 수 있는 URL보다 Header 정보의 값을 처리해야 하므로 전문성이 요구된다.

 왜 RESTful APIs를 만드는 것일까?

RESTful API를 개발하는 가장 큰 이유는 Client Side를 정형화된 플래폼이 아닌 모바일, PC, 애플리케이션 등 플랫폼에 제약을 두지 않는 것을 목표로 했기 때문이다. -즉, 2010년 이전만 해도 Server Side에서 데이터를 전달해주는 Client 프로그램의 대상은 PC 브라우저로 그 대상이 명확했다. 그렇다 보니 그냥 JSP ASP PHP 등을 이용한 웹페이지를 구성하고 작업을 진행하면 됐다.
하지만 스마트 기기들이 등장하면서 TV, 스마트 폰, 테블릿 등 Client 프로그램이 다양화되고 그에 맞춰 Server를 일일이 만든다는 것은 꽤 비효율적인 일이 되어 버렸다.
이런 과정에서 개발자들은 Client Side를 전혀 고려하지 않고 메시지 기반, XML, JSON과 같은 Client에서 바로 객체로 치환 가능한 형태의 데이터 통신을 지향하게 되면서 Server와 Client의 역할을 분리하게 되었다.


gRPC (google Remote Procedure Call)
gRPC는 google 사에서 개발한 오픈소스 RPC(Remote Procedure Call) 프레임워크입니다. 이전까지는 RPC 기능은 지원하지 않고, 메세지(JSON 등)을 Serialize할 수 있는 프레임워크인 PB(Protocol Buffer, 프로토콜 버퍼)만을 제공해왔는데, PB 기반 Serizlaizer에 HTTP/2를 결합하여 RPC 프레임워크를 탄생시킨 것이죠.

REST와 비교했을 때 기반 기술이 다르기에 특징도 많이 다르지만, 가장 두드러진 차이점은 HTTP/2를 사용한다는 것과 프로토콜 버퍼로 데이터를 전달한다는 점입니다. 그렇기에 Proto File만 배포하면 환경과 프로그램 언어에 구애받지 않고 서로 간의 데이터 통신이 가능합니다.

graphql
레스트api는 메소드와 uir를 조합해서 예측 가능하고 일정한 정보와 작업을 요청
다 좋은데 내가 필요한 정보만 딱 얻으려면 또 그떄마다 새로운 api를 만들어야 해서 넘나 귀찮다
또는 요청을 2번 보내야 하는 경우도 있는데, 그래프큐엘은 이걸 1번만 보내도 딱 돌려주도록 되어있다
수정하려면 뮤테이션
받아야 하는 정보가 딱 정해진거면 일일히 그래프큐엘처럼 클라에서 필요한걸 다 쓰기보단 레스트방식으로 uri 한줄로 처리하는게 쉽다
######################################################################################################################################

## 토픽 4. 인증과 인가

# 인증 = 로그인

# 인가 = 이미 인증 받은 사용자임을 허가
쿠키 - 세션
메모리 휘발성이면 좀 위험하고 메모리도 부족할수도 있고
그렇다고 디비에 저장하자니 에바고…
게다가 서버가 여러대면 더 방법 없어짐
메모리형 디비(레디스)를 쓰면 좀 해결이 됨
또 보통은 쿠키를 비밀키로 암호화 해서 보내기 떄문에, 이 쿠키 내부의 내용을 클라이언트가 조작할 수가 없게 되어있음. 조작하려면 데이터를 만들어서 서버의 비밀키로 해시를 해야 하기 떄문…그러나 무튼 서버가 데이터를 가지고 있어야 한다는건 분명히 무리가 있다
이 문제를 해결하기 위해 요즘은 토큰을 쓴다
토큰을 서버에서 만들어서 클라에게 주고  서버는 아무것도 저장 x
헤더 페이로드 veryfy시그니쳐 3개가 들어있다
페이로드를 base64로 디코딩하면 누가 누구에게 발급했는지, 유효 날짜, 서비스가 알려주는 데이터 = claim
헤더 = jwt 타입을 명시하고, 알고리즘으로 해시 알고리즘이 지정된다
헤더, 페이로드, 그리고 서버에서만 아는 비밀키로 해시 알고리즘에 따라 돌리면 마지막인 서명값이 나오게 된다. 이로 인해서 페이로드를 변경하면 해시값이 달라지게 되므로 페이로드를 클라이언트에서 변경하는게 불가능해진다. 흠…근데 이게 의미가 있냐?
단점은 일단 사용자를 컨트롤할 수 없다 예를 들어
사용자가 pc에서 모바일 접속으로 변경된 경우 현재 세션을 끊어주는게 세션 방식은 가능한데, 토큰은 그게 안됨
또한 이 토큰을 탈취당하면 다른 사람이 접속할 수 있음
물론 쿠키도 똑같이 탈취당하면 위험한데…그게 그거 아님?
아니다…왜냐면 세션은 적어도 이게 좀 위험하다 싶으면 그 세션을 서버에서 날려버리면 되는데 토큰은 그게 안됨
물론 이걸 해결하려고 토큰 만료 시간을 매우 짧게 잡는 경우가 있음
예를 들어 수명이 매우 짧은 접근 토큰과, 수명이 매우 긴 리프레쉬 토큰 2개를 동시에 준 다음, 리프레쉬 토큰만 디비에 저장을 해둔다. 클라는 access의 수명이 끝나면 리프레쉬 토큰을 서버에 보낸다. 서버에서 그걸 디비랑 대조하고 문제가 없는 경우 access 토큰을 재발급한다
이렇게 하면
만약 엑세스 토큰이 빼앗겨도 오래 쓰는건 안되는거고
강제로 누군가를 로그아웃 시키려면 리프레시 토큰을 디비에서 지워버리면 엑세스 토큰 재발급이 안됨
쿠키의 동작 순서
클라이언트가 페이지를 요청한다. (사용자가 웹사이트에 접근)
웹 서버는 클라이언트가 보낸 Request-Header에 쿠키가 없음을 판별하고 통신 상태(UserId, Password, 조작상태, 방문횟수 등)을 저장한 쿠키를 response한다.
생성된 쿠키를 헤더에 포함시켜 응답한다.
넘겨받은 쿠키는 클라이언트가(웹 브라우저) 가지고 있다가(로컬 PC에 저장)다시 서버에 요청할 때 요청과 함께 HTTP 헤더에 쿠키를 넣어서 전송한다.
서버에서는 쿠키 정보를 읽어 이전 상태 정보를 확인할 후 응답한다.

 세션 특징
웹 서버에 웹 컨테이너의 상태를 유지하기 위한 정보를 저장한다.
쿠키를 기반으로 두고 있지만, 쿠키와 달리 사용자 정보 저장을 서버 측에서 관리
브라우저를 닫거나, 서버에서 세션을 삭제했을 때만 삭제가 되므로, 쿠키보다 비교적 보안이 좋다.
각 클라이언트에 고유 Session ID를 부여한다. Session ID로 클라이언트를 구분해 각 요구에 맞는 서비스를 제공

 세션의 동작 순서
클라이언트가 서버에 접속시, 세션 ID를 발급한다.
서버가 응답할 때 HTTP 헤더(Set-Cookie)에 Session ID를 포함해서 전송
쿠키에 Session ID를 JSESSIONID라는 이름으로 저장 (Set-Cookie: JSESSIONID=xslei13f)
클라이언트는(웹 브라우저) 다시 페이지에 접속할때, 다음 요청 때 부여된 Session ID가 담겨 있는 쿠키를 HTTP 헤더에 넣어서 전송(Cookie: JSEESIONID=xslei13f)
서버는 Request Header에 쿠키정보(세션ID)로 클라이언트를 판별
 SESSION ID 보안의 취약점
세션 해킹: 홈페이지 관리자의 세션 아이디를 탈취 => 쿠키값을 관리자의 세션 아이디로 변경한다. => 관리자 권한으로 이용
예방법: 세션에 로그인 했을 때의 IP를 저장 => 페이지 이동 시마다, 현재 IP와 세션의 IP/브라우저 정보(UserAgent)가 같은지 검사
###################################################################
## 토픽 5. sop and cors
1번 도메인 브라우저에서 2번 사기닷컴으로 api 요청을 할 수 있으면 안된다
1번 도메인으로 로그인을 했다고 가정하면 해당 쿠키나 토큰이 브라우저에 저장되어 있을 것이다.
그러면 이제 1번 도메인으로 로그인을 하면 서버로부터 내 정보를 받을것인데
이 데이터를 2번 사기닷컴에 보내버릴 수 있게 된다면?
그럼 망한다
즉, 1번 도메인에서 2번 도메인으로 무언가 데이터를 주고 받는 행위는 금지되어야 한다
요청을 못보내도록 브라우저는 이를 용납하지 않고 cors 에러를 띄운다

정리하면
이걸 못하게 막는건 SOP(동일 출처 정책)
이 출처가 달라도 되게 할려면 CORS를 허용해라
요청을 받는 백엔드쪽에서 이걸 허락할 다른 출처를 명시하면 된다

브라우저는 이렇게 CROSS ORIGIN 요청을 보낼때에는 요청에 ORIGIN이라는 헤더를 추가한다
이 ORIGIN에는 요청하는 쪽의 sheme(포로토콜)과 도메인, 포트가 들ㅇ있다
그러면 이제 백엔드는 응답의 헤더에 Access-control-Allow-Origin 정보를 실어서 보냄. 만약 등록된 URL이면 여기에 들어있음. 그럼 이제 크롬에서 내가 ORIGIN에 넣어서 보낸 도메인이 이 돌아온 응답의 ACAO 안에 들어있으면 ok 해줌. 이게 안전하면 이제 데이터를 받아온다.

만약 브라우저가 보내던 요청이 토큰이나 식별 정보가 담긴거면 좀 더 엄격해짐
일단 브라우저가 이걸 보낼라면 credentials true를 해야되고
받는쪽에서도 아무거나 다 됨은 안되고 보내는 쪽의 출처-웹페이지 주소 정확하게 명시해서 Access-control-Allow-Origin-Credentials 를 true로 해줘야됨
근데 이런건 get이나 post에서만 사용되는거고 이런걸 심플 리퀘스트라고 함
put이나delete같은 요청은 preflight라는 요청을 먼저 보내서 이 요청이 안전한지 미리 확인을 하고 이게 되면 그 다음에 이제 ㄱㄱ 이걸 프라플라이트 리퀘스트라함
######################################################################################################################################
## 토픽5. 데이터 전송 프로토콜
- WebSocket
- hls
- WebRTC
###################################################################
경험 1. 채팅 서버 개발 경험
1. 개발 구조
2. 선택 근거
###################################################################
경험 2. 미디어 서버 개발 경험
1. 개발 구조
당근마켓
서버 - 미디어 서버에서 클라우드페어 스트림을 연동해서 작동
클라이언트 - 클라우드페어 스트림 플레이어

나
서버 - ffmpeg를 통해서 업로드된 영상을 hls 방식으로 인코딩
Your node.js server is not doing the transcoding. The ffmpeg installed on your OS is.
So using cluster in node won't help at all.
You can use -threads flag in ffmpeg to use multiple cores.

그런데 노드는 사실상 이 큐가 큰 의미가 없는데...이게 언제 의미가 있느냐
node 내부의 6개의 사이클 내부에 있는 큐보다 요청이 더 빠르게 많이 들어올 때...!
그 때는 요청이 큐에서 버려지기 때문에, 더 큰 큐를 만들어서 쓰기 위해서는 직접 하나 만들어 쓰면 됨
영상 인코딩 요청이 많을 것이라고 가정한다면?
따라서 실제로 썻던 방법은 일단 업로드를 하는걸 예약을 한다
그리고 클라에게는 기다리지 않도록 미리 결과를 돌려줘야 한다.
이 작업을 하기 위해서 큐에 일단 담으면 된다. 메모리에 큐
이제 큐를 돌면서 하나씩 처리를 해줘야 함
처리가 끝나면 디비에 video url에 완료 처리를 해주면 됨
근데 만약에 큐가 날아가버리면 어캄? 이걸 위해서 좀 안정적인걸 쓰면 좋겠다
그게 카프카같은거인듯...

클라이언트 - hls 플레이어 사용했음

2. 선택 근거

실시간 라이브 개발 경험 - 클라이언트에서 개발 경험이 어려웠다
1. 개발 구조
2. 선택 근거
###################################################################
경험3. mmorpg 실시간 동기화 개발 경험 - 트래픽 해결이 어려웠다
1. 개발 구조
통신은 구글프로토버프
서버와 클라이언트 모두 라이트버퍼, 리드버퍼를 만들고 사용
클라이언트는 유니티의 특성상 싱글스레드이기 때문에, 스레드간 데이터 공유를 위해 큐를 사용
서버는 패킷을 모아 보낼 수 있게 하기 위해서 잡큐를 사용함

2. 선택 근거
서버 몇 명이 버텼냐
시간이 얼마나 걸렸는지 재봣냐
##############################################################
테스트드리븐
##############################################################
카프카 조사
##############################################################
몽고디비 정확하게 조사
##############################################################
검색어가 굉장히 이상하게 들어와도 찰떡같이 알아먹고 조회하려면 어떻게 해야함?
##############################################################
데이터베이스의 데이터가 대량으로 변경되어야 하는 경우라면 대체 뭘 어케 해야함?
##############################################################
서로 다른 n명의 유저가 서로 다른 서버의 세션에 하나의 룸에 들어있다. 다른 서버로 접속하는 경우 어떻게 하나의 룸 접속 동기화를 할 것인가?
##############################################################
스트리밍을 구현한다면 어떻게 할 것인가?
부동산이라는 도메인에 초점을 맞춘다면 어떤 기술적인 질문이 나올 수 있는지 생각할 것
주소 검색 방식
주소 저장 방식
주소가 바뀐다면?
지도로 실시간 동기화 구현한다면 어떻게 할까?
굳이 가지 않고 중개사를 통해 실시간 라이브로 매물을 볼 수 있게 해준다면?
매물의 신뢰도를 보장하기 위해서 어떤 방법을 쓸 수 있을까?
계약의 편리성을 위해 온라인 서명을 개발하려고 한다고 가정하면 나올 수 있는 기술적인 질문이 뭐가 있을까?
##############################################################
프록시 서버 설정이 무엇이고 관련 에러와 해결 방법은 무엇인가?
##############################################################
N명의 유저가 거대한 오픈월드에 접속해서 이동 동기화를 해야할 때 어떻게 하면 될까?
###################################################################
웹알티씨와 웹소켓의 차이는 무엇이고 장단점은 무엇인가?
###################################################################
WebFlux 쓰시나요?
###################################################################
영상 스트리밍을 끊기지 않고 하려면 어떻게 해야 하는가? 웹알티씨와 웹소켓으로 비교하라
###################################################################
1G 파일이 있는데 이 파일을 서버를 통해 클라이언트로 전달하고 싶다.
이때 이 파일을 한 번에 읽어 전달하면 cpu를 많이 사용하게 될텐데
어떻게 성능을 개선할 수 있을까?
###################################################################
Stream API
##################################################################
###################################################################
ffempeg 영상 처리 hls 동작 원리는?
###################################################################
webrtc 동작 원리
##############################################################
미리 인코딩한 영상이 아니라 실시간으로 라이브 스트리밍을 하려면 인코딩을 해서 클라에게 브로드캐스팅 해야하는데 어떻게 하면 안끊기고 빠르게 클라에게 보낼 수 있나?
#############################################################
규모 확장에 따른 시스템 구성
웹서버와 데이터베이스서버를 분리하자
수직적 규모 확장의 단점은 무한 확장이 불가능하고 spof 장애 대응이 어렵다는 점
따라서 수평적 확장이 좋다. 이는 샤딩이다
로드밸런서를 써서 웹서버의 부하 분산을 줄인다
데이터베이스 다중화로 부하 분산을 줄인다. 읽기는 slave에게 맞긴다
병렬처리 되고 안전하고 다 좋은데 

응답 시간 개선(정적 파일, 이미지, 동영상)
캐시(갱신은 적지만 참조 참조되는 데이터, 만료 기간 설정, 일관성, 장애 대응을 위한 분산, 커다란 크기, LRU)
cdn(제 3자가 제공하는 캐시서버라고 보면 된다)

웹 계층 수평 확장하기
무상태 웹 계층으로 만들어야 한다
상태 정보는 공유 저장소에 보관해야 한다(데이터베이스)

데이터베이스 수평 확장하기
샤딩 - 모든 샤드는 동일한 스키마지만 중복되지 않고, 어떤 샤드에 저장할지는 샤딩 키로 결정하는데 적절하게 분산될 수 있도록 올바른 샤딩키 전략을 쓰는게 중요하다
만약 너무 많은 데이터로 하나의 샤드로 감당이 안되거나 불균형 문제로 샤드 소진이 일어나면 샤드키를 개선하고 데이터를 재배치해야 한다 - 안정 해시 기법으로 해결 가능
유명인사 문제가 생길 수 있다
조인하기 힘들다
여기까지의 구조는 아래와 같다

데이터 센터
지리적 라우팅: 사용자의 IP를 기반으로 올바른 데이터 센터로 라우팅
어떻게 올바른 지리를 찾을 것인지 어려운 점이 있다
데이터 센터끼리의 동기화가 어렵다

메세지 큐의 사용
서버간 결합이 느슨해져 확장성이 좋고 책임이 분리되어 기능 확장에 좋다
로그, 메트릭과 같은 값들을 처리하기에 좋다



처리율 제한 장치
API 요청 횟수가 임계치를 넘어서면 이후 모든 호출은 중단된다.
사용자는 초당 2회 이상 새 글을 올릴 수 없다.
같은 IP로 하루에 10개 이상의 계정을 생성할 수 없다.
같은 디바이로 주 5회 이상 리워드를 요청할 수 없다.
도스 공격 방지 가능
비용 절감 및 서버 과부화 방지
일반적으로 미들웨어를 만들어 서버와 클라 사이에 둔다.
처리율 제한 알고리즘의 예시는 아래와 같다.
토큰 버킷 알고리즘: 게임의 입장권과 같은 개념이다
누출 버킷 알고리즘; 위와 비슷한데, 처리 속도가 정해져 있다
고정 윈도 카운터 알고리즘
등등…
카운터는 REDIS를 활용해서 메모리에서 관리한다
일반적으로 처리율 제한 장치는 Header를 이용해 해당 정보를 클라이언트에게 전달한다.
X-Ratelimit-Remaining
윈도 내 남은 처리 가능 요청 수
X-Ratelimit-Limit
매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
X-Ratelimit-Retry-After
한도 제한에 걸리지 않기 위해 몇 초 뒤에 요청을 다시 보내야 하는지 알림
분산 환경에서 병렬 서버가 레디스의 값을 읽을 때 경쟁 조건이 발생할 수 있으며 락을 쓰면 느려지니까 SORED SET을 쓰면 된다(왜?)





###################################################################
알림 시스템 설계

데이트베이스와 캐시는 사용자 정보나 단말 정보 알림 템플릿등을 저장하고 조회
메세지큐는 의존성을 제거하고 spof를 제거한다
작업서버는 서드파티의 확장성을 위해 분리한다
그러나 데이터 손실(알림 데이터를 디비에 보관하고 재시도 메카니즈 필요). 알림 중복 방지, 사용자의 알림 설정 상태등을 구현

###################################################################
피드 시스템 구현
###################################################################
채팅 시스템 구현
응답 지연이 낮은 1:1 채팅 기능 제공
최대 100명까지 참여할 수 있는 그룹 채팅 기능 제공
사용자 접속 상태 표시
하나의 계정으로 여러 단말에서 동시 접속 지원
푸시 알림

서비스 탐색 서비스는 클라이언트가 접속할 채팅 서버의 DNS 호스트명을 클라이언트에게 알려주는 역할을 한다. 

실시간으로 메시지를 주고받기 위해 클라이언트는 채팅 서버와 웹소켓 연결을 끊지 않고 유지한다.
채팅 서버는 클라이언트 사이에서 메시지를 중계하는 역할을 담당한다.
접속 상태 서버는 사용자의 접속 여부를 관리한다.
API 서버는 로그인, 회원가입 등 나머지 전부를 처리한다.
알림 서버는 푸시 알림을 담당한다.
키-값 저장소는 채팅 이력을 보관하고 사용자에게 이전 채팅 이력 정보 제공을 담당한다.
채팅 시스템이 다루는 데이터는 보통 두 가지다.
사용자 프로필, 설정, 친구 목록과 같은 일반적인 데이터
채팅 이력처럼 채팅 시스템에 고유한 데이터
우리는 이 두 개의 데이터 유형과 읽기/쓰기 연산 패턴을 이해하고 저장소를 선택해야 한다.
1번의 경우 데이터 안정성을 보장하는 관계형 데이터베이스가 적합하고
2번은 키-값 저장소와 같은 NoSQL이 유리하다.
채팅 이력 데이터의 양은 엄청나게 많고 최근에 주고받은 메시지가 가장 빈번하게 사용되며, 검색 기능이나 멘션 같은 기능도 잘 지원해야 한다. 키-값 저장소는 수평적 규모 확장이 쉽고, 데이터 접근 지연시간이 낮기 때문에 채팅 이력을 보관하는 저장소로 사용하기에 적합하다.
데이터 모델
그렇다면 키-값 저장소에 저장될 메시지 데이터는 어떻게 보관해야 할까?
메시지의 키가 되는 ID, 메시지를 보내는 사람, 받는 사람, 메시지 컨텐츠, 메시지 생성 일자 등이 필요할 것이다.
여기서는 메시지의 ID가 중요하다.
메시지 ID는 고유해야 하며 정렬이 가능해야 한다. 즉, 새로운 ID는 이전 ID보다 큰 값을 가지고 있어야 한다.
가장 적합한 메시지 ID 생성 방법은 몇 가지가 있는데, 첫 번째 방법은 분산 시스템의 유일 ID 생성기 설계에서 살펴본 스노플레이크 같은 전역적 64-bit 순서 번호 생성기를 이용하는 것이고 두 번째 방법은 지역적 순서 번호 생성기를 이용하는 것이다.
여기서 지역적 순서 번호 생성기란 같은 그룹 안에서만 유일성을 보증하는 순서 번호 생성기를 말한다.

사용자가 시스템 로그인을 시도한다.
로드밸런서가 API 서버들 중 하나로 요청을 보낸다.
API 서버가 인증 처리를 완료하면 서비스 탐색 기능이 동작하여 최적의 채팅 서버를 찾는다.
사용자는 최적의 채팅 서버로 선택된 채팅 서버 2와 웹소켓 연결을 맺는다.


소규모 그룹 채팅인 경우 큐에 복사하는 작업 비용이 크지 않기 때문에 이러한 방식이 적합하다. 하지만 대규모의 사용자를 지원해야 하는 그룹 채팅이라면 같은 메시지를 모든 사용자의 큐에 복사하는 일은 바람직하지 않다.
 
 


















