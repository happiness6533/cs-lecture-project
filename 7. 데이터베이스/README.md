## 데이터베이스

```mysql
-- 조인 x --
SELECT 
    DISTINCT 
    애트리뷰트 AS 별명
    AVG(애트리뷰트) AS 별명, 
    COUNT(애트리뷰트) AS 별명, 
    MAX(애트리뷰트) AS 별명, 
    MIN(애트리뷰트) AS 별명,
    SUM(애트리뷰트) AS 별명,
    CASE WHEN 
        애트리뷰트1 조건 THEN 값 변경
        애트리뷰트2 조건 THEN 값 변경
        END AS 별명 => CASE는 추가 정리가 필요함
FROM 
    테이블 이름 AS 별명
WHERE 
    애트리뷰트 BETWEEN LIKE IN (AND/OR) (IS NULL / IS NOT NULL) (등호/부등호)
    애트리뷰트 = IN ANY EXISTS ALL (중첩질의) => 중첩 질의 구조는 조인으로 바꿔 할 수 있다
GROUP BY 
    애트리뷰트 => 이렇게 되면 해당 애트리뷰트로 행들이 합쳐지므로 SELECT 절에 반드시 그룹화 애트리뷰트 혹은 집단함수만 쓸 수 있다
HAVING
    애트리뷰트에 대한 조건 => 그룹화 애트리뷰트 또는 집단함수에 대해서만 조건 적용 가능
ORDER BY 
    애트리뷰트1 (ASC/DESC), 애트리뷰트2(ASC/DESC)        

-- 조인 o --
SELECT 
    DISTINCT  
    애트리뷰트 AS 별명
    AVG(애트리뷰트) AS 별명, 
    COUNT(애트리뷰트) AS 별명, 
    MAX(애트리뷰트) AS 별명, 
    MIN(애트리뷰트) AS 별명,
    SUM(애트리뷰트) AS 별명,
FROM 
    테이블1 이름 AS 별명
    테이블2 이름 AS 별명
    (중첩질의) 테이블3별명
WHERE 
    테이블1.애트리뷰트 = 테이블2.애트리뷰트 => 동등조인
    테이블1.애트리뷰트 = 테이블1.애트리뷰트 => 내부조인(거의 안씀)
GROUP BY 
    애트리뷰트 => 이렇게 되면 해당 애트리뷰트로 행들이 합쳐지므로 SELECT 절에 반드시 그룹화 애트리뷰트 혹은 집단함수만 쓸 수 있다
HAVING
    애트리뷰트에 대한 조건 => 그룹화 애트리뷰트 또는 집단함수에 대해서만 조건 적용 가능
ORDER BY 
    애트리뷰트 (ASC/DESC)

-- 기타 --
INSERT INTO 릴레이션(애트리뷰트1, ..., 애트리뷰트n) VALUES (값1, ..., 값n)
INSERT INTO 릴레이션(애트리뷰트1, ..., 애트리뷰트n) 셀렉션 연산으로
DELETE FROM 릴레이션 WHERE 조건
UPDATE 릴레이션 SET 애트리뷰트 = 값 또는 식[, …] WHERE 조건
DATE => 시간만 추출 => HOUR(DATE)
```
###################################################################
인덱스 페이지

인덱스를 쓰면 검색이 빨라진다

인덱스를 쓰면 변경 작업을 하면 더 느려진다. 왜냐면 비트리의 특성상 페이지 분할이 일어나기 때문이다. 예를 들어 새로운 데이터를 넣는데 칸이 다 차면 페이지 분할로 페이지를 새로 만들어야 하고, 새로운 페이지를 가르킬 데이터를 부모 페이지에 입력해야 하는데, 이 경우 부모도 연쇄적으로 분할이 일어나야 할 상황이 생길 수 있다

참고로 DELETE와 UPDATE 연산도 느려진다. UPDATE와 DELETE는 기존의 인덱스를 삭제하지 않고 ‘사용하지 않음’ 처리를 해준다. 만약 어떤 테이블에 UPDATE와 DELETE가 빈번하게 발생된다면 실제 데이터는 10만건이지만 인덱스는 100만 건이 넘어가게 되어, SQL문 처리 시 비대해진 인덱스에 의해 오히려 성능이 떨어지게 될 것이다.
###################################################################
비트리

노드 안은 배열로 정렬이 되어있다. 실제 메모리 상에 차례대로 저장이 되어있는 것이다. 같은 노드 공간의 데이터들끼리 굳이 자식 노드처럼 참조 포인터 값으로 접근할 필요가 없다. 이는 즉, 같은 노드 상 데이터를 탐색할 때는 포인터 접근을 하는 것이 아니라 실제 메모리 디스크에서 바로 다음 인덱스의 접근을 하는 것이다.

하나의 노드가 가지는 데이터 개수가 많아질수록 포인터 개수는 확연히 줄어들고, 트리 내에서 다루는 데이터가 많아질수록 이러한 차이는 더욱 커질 것이다.
###################################################################
클러스터 인덱스 = 인덱스 페이지에 루트 페이지랑 리프 페이지 다 있음
보조 인덱스 = 인덱스 페이지는 루트부터 리프 페이지까지 있고, 실제 데이터는 데이터 페이지 따로 있음, 데이터 페이지는 정렬 안되어 있고, 인덱스 페이지의 리프 페이지에 페이지 번호 + 오프셋이 기록되어 있음
###################################################################
스토어드 프로시저 = sql인데 프로그래밍이 좀 되는 것
###################################################################트리거 = insert update delete의 이벤트가 발생할때 추가로 작동하는, 테이블에 미리 정의해둔 실행 코드, 백업 용도로 쓰기에 좋다
##############################################################
비관계형 데이터베이스
키벨류 베이스: 엑세스 속도는 빠르지만, SCAN에는 용이하지 않다. 분산 저장시 용이하다. 레디스
다큐먼트 베이스: 테이블의 스키마가 유동적, 즉 레코드마다 각각 다른 스키마를 가질 수 있다.
빅테이블 베이스
그래프 베이스
##############################################################
관계형 데이터베이스와 비관계형 데이터베이스의 차이점과 장단점

수평적 확장성 = 노에스큐엘 = 서버 대수를 늘리면 이 몽고디비 가용성이 늘어난다

수직적 확장성 = 에스큐엘 = 서버 성능을 올리면 이 마이에스큐엘 가용성이 늘어난다

NoSQL은 비관계형 모델을 이용하는 데이터 저장을 말하는 것이다. NoSQL 데이터베이스는 기존의 관계형 데이터베이스보다 더 융통성 있는 데이터 모델을 사용하고 데이터의 저장 및 검색을 위한 특화된 메커니즘을 제공한다. 이를 통해 NoSQL 데이터베이스는 단순 검색 및 추가 작업 있어서 매우 최적화된 키-값 저장 기법을 사용하여 응답속도나 처리효율 등에 있어서 매우 뛰어난 성능을 나타낸다.

관계형 모델을 사용하지 않으며 테이블 간 연결해서 조회할 수 있는 조인 기능이 없다.
데이터 조회를 위해 직접 프로그래밍하는 등의 비SQL 인터페이스를 통한 데이터 접근
대부분 여러 데이터베이스 서버를 묶어서(클러스터링) 하나의 데이터베이스를 구성
관계형 데이터베이스에서는 지원하는 데이터 처리 완결성(Trascation, ACID 지원)이 보장되지 않음
데이터의 스키마와 속성들을 다양하게 수용하고 동적으로 정의(Schemaless)
데이터베이스의 중단없는 서비스와 자동 복구 기능 지원
대다수의 제품이 Open Source로 제공
대다수의 제품이 고확장성, 고가용성, 고성능 특징을 가진다.
관계형 데이터베이스보다 훨씬 다양한 방식으로 빠르게 바뀌는 대량의 비정형 데이터를 처리할 수 있음

정리하면 NoSQL은 초고용량 데이터 처리등 성능에 특화된 목적을 위해 비 관계형 데이터 저장소에 비 구조적인 데이터를 저장하기 위한 분산저장 시스템이라고 볼 수 있다.

###################################################################샤딩
하나의 테이블에 데이터가 너무 많은 경우 다수의 테이블로 나누는 방법(가로)
###################################################################
몽고디비의 장점

RDBMS에 비해 저렴한 비용으로 분산 처리와 병렬 처리가 가능(왜?)
비정형 데이터 구조 설계로 설계 비용이 감소
관계형 데이터베이스의 relation과 join 구조를 linking과 embedded로 구현하여 성능이 빠름
Big Data 처리에 효과적: 많은 서버로 확장이 가능(데이터 중복이 생기더라도 테이블을 정규화 시키지 않아도 큰 테이블에 담아 저장)
Scale out 구조를 채택하여 서버 확장에 용이하며 더 많은 데이터를 저장?
Document based 구조로 데이터 모델의 유연한 변화가 가능
json 구조로 RDBMS 테이블 구조에 비해 데이터를 직관적으로 파악
Auto Sharding
###################################################################
몽고디비의 단점

sharding 방식을 사용해서 큰 테이블을 여러 서버에 나누어 저장하기 때문에 fault tolerancy를 위해 데이터는 반드시 두 개 이상의 서버에 저장된다. 따라서 어떤 데이터가 update 되었을 때, NoSQL은 중복 저장된 서버들에 해당 update가 적용되기까지는 시간이 걸린다. RDBMS는 모든 서버를 update 되기전까지는 해당 데이터 또는 테이블에 lock을 걸어 읽기 금지를 한다. 따라서 데이터에 대한 일관성이 보장된다. 하지만 NoSQL에서는 lock을 하게 될 경우 느려지므로 RDBMS와 같은 lock을 하지 않기 때문에 데이터 일관성이 항상 보장되지 않는다. => 이걸 감안하고도 써야하는 이유가 뭐지…? 그리고 일관성이 보장 안되면 이걸 어떻게 복구함…?

몽고디비는 다큐먼트 베이스기 때문에 조인과 같은 연산을 최적화하기 어렵다.
많은 인덱스를 사용하려면 충분한 메모리가 필요. 인덱스 구조가 메모리에 저장
###################################################################
관계형 데이터베이스에서 데이터의 개수가 매우 많은 테이블을 설계해야 한다

대량의 데이터가 하나의 테이블에 집약되어 있고 하나의 하드웨어 공간에 저장되어 있으면 성능 저하가 있을 확률이 크다. 이런 경우 트랜잭션이 분산 처리될 수 있도록 테이블 단위에서 분할을 설계할 필요가 있다.

분할은 파티셔닝을 적용하거나 PK에 의해 테이블을 분할하는 방법을 적용할 수 있다. Oracle의 경우 크게 List Partition(특정 값 지정), Range Partition(범위), Hash Partition(해쉬적용), Composite Partition(범위와 해쉬가 복합)등이 가능하다.

데이터가 대량으로 많이 있을 때 논리적으로는 하나의 테이블로 보이지만 물리적으로는 여러 개의 테이블 페이지에 쏘개어 저장될 수 있는 구조의 파티셔닝을 사용하면 성능을 개선할 수 있다.

Range Partition
예를 들어 요금 테이블에 PK가 요금일자+요금번호로 구성되어 있고 데이터 건수가 대용량 테이블의 경우 하나의 테이블로는 너무 많은 데이터가 존재한다. 요금의 특성상 월 단위로 데이터를 처리하는 경우가 많으므로 PK인 요금일자의 년+월을 이용하여 12개의 파티션 테이블(요금_0401~요금_0412)을 만들 수 있다. 테이블이 날짜 또는 숫자값으로 분리가 가능하고 각 영역별로 트랜잭션이 분리된다면 이렇게 Range Parition을 적용한다. 또한, 이 파티셔닝은 데이터 보관주기에 따라 테이블에 데이터를 쉽게 지우는 것이 가능하므로 (파티션 테이블 드랍 가능) 데이터 보관 주기에 따른 테이블 관리가 용이하다는 장점을 가진다.

List Partition
지점, 사업소, 사업장, 핵심적인 코드값 등으로 PK가 구성되어 있고 대량의 데이터가 있는 테이블이라면 값 각각에 의해 파티셔닝이 되는 List Partition을 적용할 수 있다. 대용량 데이터를 특정값에 따라 분리하여 저장할 수 있으나 Range Partiton과 같이 데이터 보관주기에 따라 쉽게 삭제하는 기능은 제공될 수 없다.

Hash Partition
지정된 Hash 조건에 따라 해쉬 알고리즘이 적용되어 테이블이 분리되며 설계자는 테이블에 데이터가 정확하게 어떻게 들어갔는지 알 수 없다. 이 기능 역시 데이터 보관 주기에 따라 쉽게 삭제하는 기능은 제공될 수 없다.


하나의 테이블에 대량의 로우가 존재하는 경우
인덱스를 생성할 때 인덱스의 Tree 구조가 너무 커서 인덱스의 크기가 커지게 되고 그렇게 되면 인덱스를 찾아가는 단계가 깊어지게 되어 디스크 I/O를 많이 유발하고 조회의 성능에 영향을 미치게 된다. 물론 조회의 성능에는 영향을 미치는 정도가 작지만 데이터를 입력 / 수정 / 삭제하는 트랜잭션의 경우 인덱스의 특성상 일량이 증가하여 성능저하를 유발할 수 있다.

하나의 테이블에 많은 수의 칼럼이 존재하는 경우
데이터가 디스크의 여러 블록에 존재해서 디스크에서 데이터를 읽는 I/O량이 많아지게 되어 성능이 저하되게 된다. 이것을 로우 체이닝과 로우 마이그레이션이라고 한다.

로우체이닝
로우 길이가 너무 길어서 데이터 블록 하나에 데이터가 모두 저장되지 않고 두 개 이상의 블록에 걸쳐 하나의 로우가 저장되어 있는 형태이다.

로우마이그레이션
데이터 블록에서 수정이 발생하면 수정된 데이터를 해당 데이터 블록에서 
저장하지 못하고 다른 블록의 빈 공간을 찾아 저장하는 방식이다.

이렇게 많은 컬럼을 가지고 있는 테이블에 대해서는 트랜잭션이 발생할 때 어떤 칼럼에 대해 집중적으로 발생하는지 분석하여 테이블을 1:1 관계로 분리해서 쪼개어주면 디스크 I/O가 감소하게 되어 성능이 좋아질 수 있다.

결론
칼럼의 수가 적지만 데이터 용량이 많아 성능 저하가 예상이 되는 경우 테이블에 대해 파티셔닝 전략을 사용한다. 이때 임의로 파티셔닝할 것인지 데이터가 발생되는 시간에 따라 파티셔닝을 할 것인지를 고려한다. 칼럼 수가 많은 경우 트랜잭션 특성에 따라 테이블을 1:1 형태로 분리할 수 있는지 검증하면 된다.
###################################################################
인덱스

추가적인 쓰기 작업과 저장 공간을 활용하여 데이터베이스 테이블의 검색 속도를 향상시키기 위한 자료구조

인덱스를 왜 쓰는가?

특정 조건을 만족하는 행을 빠르게 찾기 위해서

테이블 만들 때 인덱스 거는 방법

프라이머리키는 따로 안걸어도 자동으로 인덱스가 생긴다

a, b에 멀티인덱스를 생성한 경우의 트리 예시


이미 존재하는 테이블에 인덱스 거는 방법





멀티 인덱스를 쓰고 추가 인덱스를 걸어야 하는 예시


해당 테이블이 어떤 인덱스를 쓰는지 보는 방법

이걸 내가 직접 세팅하고 싶으면


커버링 인덱스란?


인덱스는 사용 빈도가 낮고 column의 선별도가 나쁜 곳에는 쓰지 말아야 한다.

인덱스의 장점
테이블을 조회하는 속도와 그에 따른 성능을 향상시킬 수 있다.
키 값을 기초로 하여 테이블에서 검색과 정렬 속도를 향상시킨다.
인덱스를 사용하면 테이블 행의 고유성을 강화시킬 수 있다.
테이블의 기본 키는 자동으로 인덱스 된다.
아래의 특성을 가지면 인덱스를 쓰는게 좋다
INSERT, UPDATE, DELETE가 자주 발생하지 않는 컬럼
JOIN이나 WHERE 또는 ORDER BY에 자주 사용되는 컬럼
데이터의 중복도가 낮은 컬럼
필드에 저장된 값을 찾는 작업이 예상되는 경우
필드의 값을 정렬하는 작업이 예상되는 경우

인덱스의 단점
컬럼의 값이 true/fase, 성별(M/F) 등에는 인덱스를 사용하지 않는 것이 좋다.
인덱스를 관리하기 위해 DB의 약 10%에 해당하는 저장공간이 필요하다.
인덱스를 관리하기 위해 추가 작업이 필요하다.
인덱스를 잘못 사용할 경우 오히려 성능이 저하되는 역효과가 발생할 수 있다. 특히 인덱스 된 필드에서 데이터를 업데이트하거나, 레코드를 추가 또는 삭제할 때 성능이 떨어진다. CREATE, DELETE, UPDATE가 빈번한 속성에 인덱스를 걸게 되면 인덱스의 크기가 비대해져서 성능이 오히려 저하되는 역효과가 발생할 수 있다. 이유는 DELETE와 UPDATE 연산 때문이다. UPDATE와 DELETE는 기존의 인덱스를 삭제하지 않고 ‘사용하지 않음’ 처리를 해준다. 만약 어떤 테이블에 UPDATE와 DELETE가 빈번하게 발생된다면 실제 데이터는 10만건이지만 인덱스는 100만 건이 넘어가게 되어, SQL문 처리 시 비대해진 인덱스에 의해 오히려 성능이 떨어지게 될 것이다.
##############################################################
b-tree

데이터에 접근하는 시간복잡도가 O(1)인 hash table이 더 효율적으로 보일 수가 있다. SELECT 질의의 조건에는 등호(<>) 연산도 포함이 된다. Hashtable을 사용하게 된다면 = 연산이 아닌 등호 연산의 경우에 문제가 발생한다. 동등 연산(=)에 특화된 hashtable은 데이터베이스의 자료구조로 적합하지 않다.
B-Tree 인덱스는 디스크 I/O를 고려하여 관계형 데이터베이스에서 가장 일반적으로 사용되는 인덱스이고 등호 연산을 수행할 수 있다. 
이 인덱스도 크기가 커져 보조 기억 장치에 저장되게 되는데 이 또한 디스크 I/O가 발생하게 되는 것이다. 따라서 B-Tree의 깊이를 줄여야 디스크 I/O를 줄일 수 있다.
##############################################################
클러스터 인덱스
클러스터 인덱스는 데이터페이지 자체가 인덱스 키 값에 의해 물리적으로 정렬이 된다. 데이터 페이지는 리프 노드와 같다. 테이블 당 1개만 허용되고, 기본 키 설정시 자동으로 만들어진다. 테이블 자체가 인덱스다. 데이터 입력, 수정, 삭제 시 항상 정렬을 유지하고 기본적으로 접근 성능이 좋다.
그러나 스캔 방식을 생각해야 한다. 클러스터 인덱스가 없는 경우 기본적으로 Heap 테이블 스캔이(클러스터 인덱스가 없는 테이블의 경우 데이터는 추가된 순서대로 쌓이니까 힙이라 한다. 즉, 테이블 전체를 스캔하는 것) 이루어진다.
특징
- 인덱싱되지 않은 상태
- 정렬의 기준이 없음
- 데이터 페이지 내의 행들 간의 순서가 없음
- 클러스터형 인덱스가 없는 테이블

장단점
- INSERT에 유리, 순서없이 그냥 페이지 빈 곳에 새 데이터를 추가하면 됨 - SELECT에 불리. 원하는 데이터를 찾기 위해서는 모든 데이터를 스캔해보아야 함.(Table Scan)

클러스터 인덱스가 있는 경우에는 클러스터 인덱스 스캔이 이루어진다.
하지만 조건절이 없으므로 무식하게 다 읽는건 Heap 테이블 스캔이 빠르다.



넌클러스터 인덱스
데이터 페이지를 건들지 않고, 별도의 장소에 인덱스 페이지를 생성한다. 우선 인덱스 페이지의 리프 페이지에 인덱스로 구성한 열을 정렬하고 데이터 위치 포인터를 생성한다. 데이터의 위치 포인터는 클러스터형 인덱스와 달리 ‘페이지 번호 + 오프셋’이 기록되어 바로 데이터 위치를 가리킨다.
테이블 당 최대 240개 생성 가능, 인덱스 페이지를 별도로 저장, 테이블 자체는 되지 않고, 인덱스 페이지에만 정렬, 성능 증가는 정말 “Case By Case”
##############################################################
 클러스터 인덱스
쿼리를 기준으로 예를 들어보자

SELECT year(hire_date), count(*)
FROM employees
WHERE hire_date >= '1997-01-01'
GROUP BY year(hire_date);

조건절에 hire_date가 있고, 범위 탐색이다. 이 경우 hire_date에 클러스터 인덱스를 적용하면 성능이 엄청나게 향상된다. 여기서 WHERE 절만 빼보자.

SELECT year(hire_date), count(*)
FROM employees
GROUP BY year(hire_date);

여기서도 마찬가지로 hire_date에 인덱스를 건다면 어떻게 될까?
성능 향상에 도움이 안되거나, 데이터가 많아지는 경우 오히려 느려진다.



 넌클러스터 인덱스

위의 예시와 같은 쿼리이다.

SELECT year(hire_date), count(*)
FROM employees
WHERE hire_date >= '1997-01-01'
GROUP BY year(hire_date);

여기서 hire_date에 넌클러스터 인덱스를 건다면 어떻게 될까?
놀랍게도 클러스터 인덱스를 걸었을 때보다 더 빠르다.
그 이유는 넌클러스터 인덱스가 탐색 범위에 포함되었기 때문에 옵티마이저에서는 인덱스 스캔이 아닌 Non-Clustered Index Seek 방식을 선택하기 때문이다.
Index Scan은 인덱스의 모든 행을 인덱스 순서로 읽는 반면에 Index Seek은 필터 기준에 따라 일치하는 행이나 한정된 행만 찾으려고 리프 노드를 거치기 때문에 논리적 읽기 수가 훨씬 감소한다

Index Seek는 B-Tree 구조상의 Root 페이지부터 Leaf Level까지 검색 경로를 따라 수행되는 방법. Leaf Level을 제외한 상위 각 레벨에서 1페이지씩을 검색하게 된다.

Index Scan은 Leaf Level의 첫번째 페이지부터 데이터 검색을 수행하는 방법. 일반적으로 얘기하는 Table Scan과 동일한 방법이지만, 그 대상이 Leaf Level의 인덱스 페이지라는 것이다.






해당 테이블을 select 하면 insert 되어 있는 순서대로 데이터가 누적되어 있을까?
아니다. LOG_DATE, MEDIA_ID는 클러스터드 인덱스로 생성이 되어 있기 때문에 물리적으로 LOG_DATE를 정렬한 후 MEDIA_ID를 정렬하게 된다.
물리적으로 정렬을 한다는 말은 이를 두고 하는 말이다. 실제 DB의 데이터파일에 정렬이 되어 있는 상태로 디스크에 저장이 된다는 것이다.
테이블 조회를 해보면 아래와 같이 데이터가 정렬되어 있는 것을 확인할 수 있다. 

그럼 넌 클러스터드 인덱스는?
일반적으로 조회문 성능 향상을 위해서 넌 클러스터드 인덱스를 생성하여 사용하곤 한다. 허나, 이 인덱스는 클러스터드인덱스와는 다르게 물리적으로 데이터가 정렬되어 저장되지 않는다.
##############################################################
멀티 인덱스
##############################################################
정규화
제1정규화: 중복 제거
제2정규화: 
제3정규화
bcnf
##############################################################
트랜잭션
데이터베이스의 상태를 변화시키기 위해서 수행하는 작업의 단위를 뜻한다.
원자성(Atomicity)
트랜잭션의 연산은 데이터베이스에 모두 반영되든지 아니면 전혀 반영되지 않아야 한다.
트랜잭션 내의 모든 명령은 반드시 완벽히 수행되어야 하며, 모두가 완벽히 수행되지 않고 어느 하나라도 오류가 발생하면 트랜잭션 전부가 취소되어야 한다.
일관성(Consistency)
트랜잭션이 그 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 변환한다.
시스템이 가지고 있는 고정요소는 트랜잭션 수행 전과 트랜잭션 수행 완료 후의 상태가 같아야 한다.
격리성(Isolation)
둘 이상의 트랜잭션이 동시에 병행 실행되는 경우 어느 하나의 트랜잭션 실행 중에 다른 트랜잭션의 연산이 끼어들 수 없다.
수행중인 트랜잭션은 완전히 완료될 때까지 다른 트랜잭션에서 수행 결과를 참조할 수 없다.
지속성(Durability)
성공적으로 완료된 트랜잭션의 결과는 시스템이 고장나더라도 영구적으로 반영되어야 한다.

Commit 연산
Commit 연산은 한 개의 논리적 단위(트랜잭션)에 대한 작업이 성공적으로 끝났고 데이터베이스가 다시 일관된 상태에 있을 때, 이 트랜잭션이 행한 갱신 연산이 완료된 것을 트랜잭션 관리자에게 알려주는 연산이다.

Rollback 연산
Rollback 연산은 하나의 트랜잭션 처리가 비정상적으로 종료되어 데이터베이스의 일관성을 깨뜨렸을 때, 이 트랜잭션의 일부가 정상적으로 처리되었더라도 트랜잭션의 원자성을 구현하기 위해 이 트랜잭션이 행한 모든 연산을 취소(Undo)하는 연산이다.
Rollback시에는 해당 트랜잭션을 재시작하거나 폐기한다.
##############################################################
트랜잭션 격리수준
트랜잭션 격리 수준은 고립도와 성능의 Trade-off를 조절한다.
READ UNCOMMITED: 다른 트랜잭션 중 커밋되지 않은 데이터를 다른 트랜잭션이 참조할 수 있다.
READ COMMITED: 커밋이 완료된 데이터만 다른 트랜잭션에서 참조할 수 있다.
REPEATABLE READ: 트랜잭션 시작 전 COMMIT 된 데이터에만 접근할 수 있다.
SERIALIZABLE: 트랜잭션에 진입하면 락을 걸어 다른 트랜잭션이 접근하지 못하게 한다. (성능이 매우 떨어짐)



트랜잭션 격리 수준이란 트랜잭션들끼리 얼마나 고립되어있는지(잠금수준)를 나타내는 것이다.
특정 트랜잭션이 다른 트랜잭션에 의해 변경된 데이터를 볼 수 있도록 허용할지 말지를 결정하는 것이다.

격리 수준은 위에 명시된 순서로 내려갈수록 고립도가 높아지나 성능이 떨어지는 게 일반적이다.

 트랜잭션 격리 수준이 필요한 이유

트랜잭션 수준 읽기 일관성 (Transaction-Level Read Consistency)을 지키기 위해서이다.(다시 말해 동시성 제어 문제 해결을 위해서이다.)

트랜잭션 수준 읽기 일관성이란

트랜잭션이 시작된 시점으로부터 일관성 있게 데이터를 읽어 들이는 것을 말한다. 하나의 트랜잭션이 진행되는 동안 다른 트랜잭션에 의해 변경사항이 발생하더라도 이를 무시하고 계속 일관성 있는 데이터를 보여준다. (물론 트랜잭션 자신이 발생한 변경사항은 읽을 수 있다.)

 READ UNCOMMITTED (트랜잭션 레벨 0)



이 단계에서는 트랜잭션에서 처리 중인, 아직 커밋되지 않은 데이터를 다른 트랜잭션이 읽는 것을 허용한다.

 특징
Dirty Read, Non-Repeatable Read, Phantom Read 현상이 발생한다.

PHANTOM READ

- 다른 트랜잭션에서 수행한 변경 작업에 의해 레코드가 보였다가 안 보였다가 하는 현상
- 이를 방지하기 위해서는 쓰기 잠금을 걸어야 한다.

DIRTY READ

아직 커밋되지 않은 다른 트랜잭션의 데이터를 읽는 것을 의미한다.

 문제점
데이터 정합성에 문제가 많다. 그렇기에 RDBMS 표준에서는 격리수준으로 인정하지 않는다.

예시
트랜잭션 A는 테이블의 데이터를 수정중인 상태이고 아직 COMMIT 전이다.
트랜잭션 B는 트랜잭션 A가 수정중인 데이터를 조회한다. (이를 Dirty Read라고 한다.)
하지만 트랜잭션 B는 COMMIT 되지 않은 데이터를 가지고 로직을 수행한다. (문제 발생)

 READ COMMITTED (트랜잭션 레벨 1)



RDB에서 대부분 기본적으로 사용되고 있는 격리 수준으로 실제 테이블 값을 가져오는 것이 아니라 Undo 영역에 백업된 레코드에서 값을 가져온다.

 특징
Dirty Read가 발생하지 않지만(트랜잭션이 COMMIT되어 확정된 데이터만 읽는 것을 허용한다.) Non-Repeatable Read, Phantom Read 현상은 여전히 발생한다.
온라인 서비스에서 가장 많이 선택되는 격리수준이다.
DB2, SQL Server, Sybase의 경우 읽기, 공유 Lock을 이용하여 구현한다.
Oracle은 Lock을 사용하지 않고 쿼리시작 시점의 Undo 데이터를 제공한다.

 문제점
NON-REPEATBLE READ 부정합 문제가 발생할 수 있다.
READ COMMITED 격리 수준에서 실행되는 SQL 문장의 결과가 무엇인지 정확히 예측하고 있어야 한다.

 REPEATABLE READ (트랜잭션 레벨 2)



트랜잭션이 시작되기 전에 COMMIT된 내용에 대해서만 조회할 수 있는 격리수준이다.
MySQL에서는 트랜잭션마다 트랜잭션 ID를 부여하여 트랜잭션 ID 보다 작은 트랜잭션 번호에서 변경한 것만 읽게 된다.
변경되기 전 레코드는 Undo 공간에 백업해 두고 실제 레코드 값을 변경한다.

 특징
Dirty Read와 같은 현상은 발생하지 않지만 Phantom Read 현상은 여전히 발생한다.

 문제점
하나의 트랜잭션 실행시간이 길어질수록 Undo에 백업된 레코드가 많아져서 멀티 버전을 관리해야 하는 단점이 있다. (하지만 영향을 미칠정도로 트랜잭션이 오래 지속되는 경우가 없어서 READ COMMITTED와 REPEATABLE READ의 성능 차이는 거의 없다고 한다.)
또한, UPDATE 부정합와 Phantom Read가 발생할 수 있다.

 SERIALIZABLE (트랜잭션 레벨 3)

선형 트랜잭션이 특정 테이블을 읽는 경우(SELECT) 공유 잠금(shared lock)을 걸어, 다른 트랜잭션에서 해당 테이블의 데이터를 UPDATE, DELETE, INSERT 작업을 못하도록 막는다.

 특징
가장 단순한 격리 수준이지만 가장 엄격한 격리 수준으로 Phantom Read가 발생하지 않는다.

 문제점
동시 처리 능력 이 다른 격리수준보다 떨어지고 성능저하가 발생하여 데이터베이스에서 거의 사용되지 않는다.

 낮은 단계의 트랜잭션 고립화 수준을 사용할 때 발생하는 세 가지 현상



 Dirty Read (Uncommitted Dependency)



변경 후 아직 Commit 되지 않은 값 읽고, Rollback 후의 값을 다시 읽어 최종 결과 값이 상이한 현상이다.
Oracle은 다중 버전 읽기 일관성 모델을 채택하여 lock을 사용하지 않고 Dirty Read를 피해 일관성 있는 데이터 읽기가 가능하게 하였다.

 Non-Repeatble Read (Inconsistent Analysis)



한 트랜잭션 내에서 같은 쿼리를 두번 수행할 때, 그 사이에 다른 트랜잭션이 값을 수정 또는 삭제함으로써 두 쿼리가 상이하게 나타나는 비 일관성이 발생하는 것을 말한다.
(다시말해 하나의 트랜잭션 내에서 동일한 SELECT를 수행했을 경우 항상 같은 결과를 반환해야하는 REPEATABLE READ 정합성에 어긋나는 것이다.)

금전적 처리와 연결된 서비스에서 문제가 발생할 수 있다.

- 트랜잭션B에서 1번 상품의 총 투자액을 조회 => 100만원이 조회됨
- 트랜잭션A에서 1번 상품의 총 투자액을 120만원으로 바꾸고 COMMIT
- 트랜잭션B에서 1번 상품의 총 투자액을 다시 조회 => 120만원이 조회됨 (NON-REPEATABLE READ)
##############################################################
관계형 데이터베이스와 엘라스틱서치 차이

관계형 데이터베이스는 단순 텍스트 매칭에 대한 검색만을 제공함
MySql 최신 버전에서 n-gram 기반의 Full-text 검색을 지원하지만, 한글 검색의 경우에 아직 많이 빈약한 감이 있음
텍스트를 여러 단어로 변형하거나 텍스트의 특질을 이용한 동의어나 유의어를 활용한 검색이 가능
Elastic Search에서는 관계형 데이터베이스에서 불가능한 비정형 데이터의 색인과 검색이 가능
이러한 특성은 빅데이터 처리에서 매우 중요하게 생각됨
Elastic Search에서는 형태소 분석을 통한 자연어 처리가 가능
Elastic Search는 다양한 형태소 분석 플러그인을 제공
역색인 지원으로 매우 빠른 검색이 가능
##############################################################
레디스
##############################################################
디비 이중화
##############################################################
분산 처리
26 sql injection에 대해 설명하세요. 27 db 셀렉트시 락걸렸을때 해결 방법은 무엇인가요?
n - 1 문제
