## 데이터베이스

```mysql
-- 조인 x --
SELECT 
    DISTINCT 
    애트리뷰트 AS 별명
    AVG(애트리뷰트) AS 별명, 
    COUNT(애트리뷰트) AS 별명, 
    MAX(애트리뷰트) AS 별명, 
    MIN(애트리뷰트) AS 별명,
    SUM(애트리뷰트) AS 별명,
    CASE WHEN 
        애트리뷰트1 조건 THEN 값 변경
        애트리뷰트2 조건 THEN 값 변경
        END AS 별명 => CASE는 추가 정리가 필요함
FROM 
    테이블 이름 AS 별명
WHERE 
    애트리뷰트 BETWEEN LIKE IN (AND/OR) (IS NULL / IS NOT NULL) (등호/부등호)
    애트리뷰트 = IN ANY EXISTS ALL (중첩질의) => 중첩 질의 구조는 조인으로 바꿔 할 수 있다
GROUP BY 
    애트리뷰트 => 이렇게 되면 해당 애트리뷰트로 행들이 합쳐지므로 SELECT 절에 반드시 그룹화 애트리뷰트 혹은 집단함수만 쓸 수 있다
HAVING
    애트리뷰트에 대한 조건 => 그룹화 애트리뷰트 또는 집단함수에 대해서만 조건 적용 가능
ORDER BY 
    애트리뷰트1 (ASC/DESC), 애트리뷰트2(ASC/DESC)        

-- 조인 o --
SELECT 
    DISTINCT  
    애트리뷰트 AS 별명
    AVG(애트리뷰트) AS 별명, 
    COUNT(애트리뷰트) AS 별명, 
    MAX(애트리뷰트) AS 별명, 
    MIN(애트리뷰트) AS 별명,
    SUM(애트리뷰트) AS 별명,
FROM 
    테이블1 이름 AS 별명
    테이블2 이름 AS 별명
    (중첩질의) 테이블3별명
WHERE 
    테이블1.애트리뷰트 = 테이블2.애트리뷰트 => 동등조인
    테이블1.애트리뷰트 = 테이블1.애트리뷰트 => 내부조인(거의 안씀)
GROUP BY 
    애트리뷰트 => 이렇게 되면 해당 애트리뷰트로 행들이 합쳐지므로 SELECT 절에 반드시 그룹화 애트리뷰트 혹은 집단함수만 쓸 수 있다
HAVING
    애트리뷰트에 대한 조건 => 그룹화 애트리뷰트 또는 집단함수에 대해서만 조건 적용 가능
ORDER BY 
    애트리뷰트 (ASC/DESC)

-- 기타 --
INSERT INTO 릴레이션(애트리뷰트1, ..., 애트리뷰트n) VALUES (값1, ..., 값n)
INSERT INTO 릴레이션(애트리뷰트1, ..., 애트리뷰트n) 셀렉션 연산으로
DELETE FROM 릴레이션 WHERE 조건
UPDATE 릴레이션 SET 애트리뷰트 = 값 또는 식[, …] WHERE 조건
DATE => 시간만 추출 => HOUR(DATE)
```
##############################################################
핵심 키워드 총정리

메모리 주소
물리주소를 논리주소로 변환하는데 mmu
논리주소, 베이스레지스터, 한계레지스터
L1, L2, L3 캐시 레지스터

입출력장치
장치 컨트롤러 - 통신, 오류 처리, 버퍼링(데이터 레지스터, 상태 레지스터, 제어 레지스터)
메모리앱 입출력, 고정형 입출력
인터럽트 기반 입출력은 프로그래머블 인터럽트 컨트롤러를 활용
dma 입출력은 dma 컨트롤러와 입출력전용버스를 활용

프로세스와 스레드
PCB PID 컨텍스트 스위칭 영역구문 계층구조 쓰레드
프로세스간 통신
파일
공유메모리
메세지큐
파이프 - 같은 컴퓨터에서 서로 다른 두 프로세스끼리 통신
소켓 - 네트워크를 활용한 서로 다른 두 프로세스끼리 통신
cpu 프로세스 스케줄링 알고리즘
대기큐 준비큐 선점 비선점을 잘 믹싱해서 아래의 방법들 중 선택
선입선처리 최단작업우선처리 라운드로빈 최소잔여시간우선 우선순위 에이징 다단게큐 다단게피드백큐(이게 대부분 쓰임)
프로세스 동기화
공유 데이터 문제 =	해결 방법은 상호 배제, 진행, 유한대기
실행 순서 제어 문제

해결 도구
= 뮤텍스 락(공유 데이터 문제 해결)
= 세마포, 모니터(공유 데이터 문제와 실행 순서 제어 문제 모두 해결)
프로세스 데드락
발생 조건 = 상호 배제, 점유와 대기, 비선점, 원형 대기
예방 방법 = 위의 4개중 하나만 없애도 됨
회피 방법 = 이런 일이 없도록 안전상태만 만들면서 자원 할당 = 뱅커
회복 방법 = 선점, 강제 종료


메모리
메모리 스와핑
연속 할당
외부 단편화, 최초, 최적, 최악 적합
불연속 할당 - 페이징, 세그멘테이션(거의 안쓰임)
페이지, 프레임, 페이지 테이블, 페이지 테이블 베이스 레지스터, TLB, 변위, 유효 비트, 페이지 폴트, 보호 비트, 참조 비트, 수정 비트
페이지 교체 - FIFO, 최적 교체, LRU
프레임 할당 - 스래싱, 균등 할당, 비례 할당, 작업 집합 모델, 페이지 폴트 빈도

파일
파일 시스템, 포메팅
블록
연속 할당
> 외부 단편화

불연속 할당 - 연결 할당
반드시 첫 번째부터 접근해야 함
중간에 하나 고장나면 답 없음
이걸 업그레이드 = FAT 파일 시스템 = 파일 할당 테이블을 모아둔다
FAT 파일 시스템은 파티션에 FAT 영역이 있다

불연속 할당 - 색인 할당
이걸 업그레이드 = 유닉스 파일 시스템 - i-node 영역을 모아둔다
12개는 직접블록주소
13, 14, 15번째에는 단일 간저브 이중 간접 블록 주소를 저장한다
##############################################################
멀티 태스크 / 멀티 스레드 / 멀티 프로세스

싱글 코어 cpu에 프로세스(싱글 스레드)가 2개 = 멀티태스킹
싱글 코어 cpu에 프로세스(듀얼 스레드)가 1개 = 멀티태스킹/멀티스레드
듀얼 코어 cpu에 프로세스(싱글 스레드)가 2개 = 멀티태스킹 아님 / 멀티 스레딩도 아님 / 멀티프로세싱 맞음
듀얼 코어 cpu에 프로세스(듀얼 스레드)가 1개 = 멀티태스킹 아님 / 멀티 스레딩 맞음 / 멀티프로세싱 맞음
듀얼 코어 cpu에 프로세스(듀얼 스레드)가 2개 = 멀티태스킹 맞음 / 
멀티 스레딩 맞음 / 멀티프로세싱 맞음
##############################################################
쓰레드 종류

하드웨어 쓰레드
인텔의 하이퍼 쓰레딩 기술로, 물리적인 코어마다 하드웨어 쓰레드가 2개이다. 이러한 하드웨어 쓰레드는 운영체제 관점에서는 가상의 코어라고 할 수 있다. 따라서 만약에 싱글 코어 cpu에 하드웨어 쓰레드가 2개라면 os는 이 cpu를 듀얼코어로 인식하고 듀얼코어에 맞춰서 os레벨의 쓰레드를 스케줄링 한다
os 쓰레드(커널 쓰레드, 네이티브 쓰레드)
cpu에서 실제로 프로그램이 실행되는 단위. cpu 스케줄링의 실제 단위. 사용자 코드와 커널 코드 모두 os 쓰레드에서 실행한다
유저  쓰레드
스레드를 프로그래밍 언어 레벨에서 사용할 수 있게 추상화한 것
유저 쓰레드와 os 쓰레드를 어떻게 연결하는가?
원투원 모델
스레드 관리, 스케줄링을 OS가 알아서 하면 된다
한 쓰레드가 블락이 되어도 다른 쓰레드가 작동한다

매니투원 모델
여러 유저 스레드가 하나의 OS 스레드를 쓰는 모델
유저 스레드간에 스위칭이 빠르다
공유 변수 문제가 발생할 가능성이 적다
멀티코어를 활용하지 못한다
한 쓰레드가 블락이 되면 다른 스레드도 모두 블락이 된다

매니투매니 모델
짱짱맨이다
##############################################################
컨텍스트 스위칭

프로세스 또는 쓰레드 컨텍스트 스위칭을 해야하는 경우
컨텍스트 스위칭 시작
> 커널모드 진입
> cpu 레지스터의 데이터 상태 저장
> cpu 레지스터에 새로운 데이터 로드 및 세팅
> 만약 프로세스 컨텍스트 스위칭인 경우 가상 메모리 주소도 처리하기 위해서 MMU 데이터 로딩 및 TLB 데이터 리셋을 해야하며 이 과정 때문에 프로세스 컨텍스트 스위칭은 느리다
> 유저모드 진입
> 새로운 프로세스 혹은 쓰레드 실행
##############################################################cpu bound io bound

cpu 버스트가 많은 프로세스 = cpu 바운드 프로세스 = 계산 및 작업 처리 서버
io 버스트가 많은 프로세스 = io 바운드 프로세스 = api 서버

cpu바운드에서 적절한 스레드 수는 cpu 개수
경합이 일어나면 결국 컨텍스트 스위칭이 발생하니까 느려질 수 밖에 없다. 멀티 코어인 경우에 코어 개수만큼 쓰레드를 운영하는게 좋다

io 바운드에서 적절한 스레드 개수는 CPU 개수보다 더 많아도 된다. 왜냐하면 IO 작업을 하는 동안에 해당 스레드는 블락되어 큐에서 쉬고 있을거기 때문에, 코어 하나가 쉬는 시간이 있을수 밖에 없고, 그 시간에 다른 요청이 들어오면 다른 스레드가 받아서 쉬는 코어를 활용해서 일을 처리하는게 유리하기 때문이다. 그러나 이렇게 되면 IO 작업이 오래 걸릴 경우 무한히 많은 쓰레드가 생성될 가능성이 있으므로 만약 api 서버가 thread per request 방식이라면 미리 쓰레드풀에 몇 개의 쓰레드를 만들어 놓아야 유리할지 생각해 봐야 함
##############################################################
동기화

실제로 변수의 값을 바꾸는 과정을 cpu 레벨에서 보면 레이스 컨디션이 발생하는데, 이 문제를 해결하려면 아래의 조건 3개를 모두 만족해야 한다
상호배제 / 프로그레스 / 한정된 대기(암기 필수)
그리고 이러한 방법론을 적용한 해결책이 크게 뮤텍스, 세마포어, 모니터가 있다











뮤텍스 

자바에는 test_and_set(&locl)이라는 cpu 레벨의 atomic 메소드가 있다
이 메소드를 활용해서 lock을 획득한 스레드만 특정 함수의 구역에 진입할 수 있도록 한다
스핀락 방식
뮤텍스 방식
세마포어 방식세마포의 시그널과 웨이트는 같은 프로세스나 같은 코어에서 작동할 필요 없군…일종의 콜백처럼 순서를 정할 수 있음
뮤텍스는 락을 가진 애만 락을 해제 가능하지만 세마는 시그널과 웨이트를 날리는 주체가 달라도 된다 또 예를 들어즉 상호배제만 할거면 뮤텍스, 실행순서 동기화는 세마포어

모니터 내부 구현 예시실제로는 프로그래밍 언어단에서 제공하는 모니터같은걸 쓰면 그만임…예를 들어 자바는 모든 객체가 내부적으로 모니터를 가진다
자바의 모니터는 syncronized 키워드로 상호배제를 하고 cv를 하나만 가짐
모니터의 3가지는 wait 시그널대신 노티파이, 브로드캐스트대신 노티파이얼
자바 실제 예시
##############################################################
데드락

두 개 이상의 스레드 혹은 프로세스가 서로가 가지는 리소스를 필요로 하는 상태이며 조건은 4개다(암기)
리소스를 공유해서 쓸 수 없다
하나 이상의 프로세스를 취득한 상태에서 다른 프로세스가 사용하는 리소스를 기다려야 함
리소스를 남이 빼앗을 수 없다
지들끼리 순환 형태로 서로의 리소스를 기다림

# 방지 = 시스템 레벨에서
=> 위의 4 조건중 하나 충족되지 않게 디자인
2번을 방지 = 사용할 리소스를 전부 다 획득해야만 시작, 리소스가 아예 없는 경우에만 리소스를 요청할 수 있다. 근데 이러면 둘 다 확보하기 어려워서 기아에 허덕일 수 있지
3번 방지 => 기다려야 되는 놈은 양보를 한다
4번 방지 => 리소스에 순서 부여해서 무조건 오름차순으로 요청하면 됨

# 회피 = 실행 환경에서
=> 뱅커알고리즘 = 리소스 줘서 데드락 있을 것 같으면 요청 거절

# 감지 복구
=> 감지되면 프로세스를 하나씩 종료해보고 풀리면 복구
=> 리소스의 일시적인 선점 허용

# 무시

# 프로그램 레벨에서 데드락은?


##############################################################
프로세스 상태 변화 알아보자


cpu 스케줄러는 cpu에서 실행될걸 선택한다
디스패쳐는 cpu에서 실제로 실행될 수 있도록 한다. 즉 컨텍스트 스위칭, 커널모드에서 유저모드로 전환하는 역할, 적절한 위치로 프로세스 이동

이런 프로세스를 깨우고 스케줄링하는 방식들은 뭐가 있냐?
프로세스 스케줄링 방법들
먼저 온 순서대로 실행
다음 CPU 버스트 짧은거 먼저 ㄱ
남은 CPU 버스트가 제일 짧은거 먼저 ㄱ
우선순위 높은거 먼저 ㄱ
라운드로빈
멀티레벨큐 = 프로세스들을 그룹화해서 그룹마다 큐를 놔둠

인터럽트
전원 문제, IO 작업 끝, 시간 끝, 0으로 나눔(트랩), 메모리 잘못 접근(트랩)
이런 인터럽트가 발생하면 CPU는 바로 커널모드로 전환해서 커널코드를 실행함

##############################################################
# 쓰레드 퍼 리퀴스트 방식의 문제점은?
스레드 생성에 소요되는 시간 때문에 요청 처리가 느려진다
이런 경우 쓰레드 풀을 쓰면생성시간도 아끼고, 무제한 쓰레드 생성도 막을 수 있다.쓰레드풀에 쌓일 리퀘스트큐에 반드시 개수 제한을 걸어야 메모리 고갈을 막고 시스템 다운을 방지할 수 있다
############################################################### io
종류: 소켓, 파일, 파이프, 디바이스
블록 io


2. 논블록 io


만약 블록 io 방식으로 해버리면 문제가 있다

이 경우 만약에 어떤 소켓이 read를 하지 못하고 클라이언트가 ㄷ이터를 보낼때까지 블락이 되어버린다면? 다른 클라이언트가 데이터를 보내도 쓰레드가 다른 소켓의 데이터를 처리하지 못하게 된다

io 멀티플렉싱(다중 입출력)을 사용하면 해결이 된다
관심있는 io 작업들을 동시에 모니터링하고 그 중에 완료된 io 작업을 한번에 알려준다



그렇다면 논블록io는 read가 완료된 것을 어떻게 확인하는가?
=> 싱크방식 = 반복적으로 확인, 문제는 딜레이가 발생하고 cpu도 낭비한다
=> 이거 말고 async 방식
이건 콜백이나 시그널로 처리하면 되지만 이건 별로 안쓰임

# async가 뭐냐?
프로그래밍 관점: 동시 실행



 

결국 async란…?
멀티쓰레드 또는 논블록으로 동시에 일을 할 수 있다는 것



백엔드 관점에서 다시 보자

이 경우는 c에 장애가 생겨도 ab 로 확대되지 않는다

##############################################################
# 프로세스끼리 메모리 공유 어려운데 어떻게 해결하나?
##############################################################
# 프로세스간 통신에 대해 설명하자

############################################################### 메세지큐를 쓰면 대체 뭐가 좋은거고,,,노드에서 메세지 큐를 쓰면 대체 뭐가 좋아지는거지? => 이미 노드가 내부적으로 큐를 쓰고 있긴 함
############################################################### 멀티스레드에서 메세지큐를 쓰면 뭐가 좋아지는거였지?
############################################################### 노드 클러스터 운영 방법에 대해서 알아보자
##############################################################
# 멀티 스레드의 경우 스레드 수가 더 많으면 무조건 좋은가?

우선 실행하려는 프로그램이 더 작은 작업들로 쪼개서 동시에 실행할 수 있는 프로그램인 경우에만 더 많은 스레드가 이점을 가질 것이다. 그리고 스레드 개수를 늘리면 결국 컨텍스트 스위칭 비용이 많이 들 것이다. 이때 스위칭하는 것 역시 cpu가 하는 것이므로 오버헤드 비용이 늘어난다. 또한 cpu 바운드 어플리케이션은 cpu를 많이 쓰기 때문에 cpu 코어 개수 이상으로 쓰레드를 늘려도 아무런 효과가 없다. 그러나 io 바운드 어플리케이션은 io 작업이 많아서 cpu가 놀고 있는 시간이 많기 때문에 코어 수보다 스레드 수를 약 2배 늘리는 것이 더 유리할 수 있다.
##############################################################


# 싱글스레드와 멀티스레드의 차이는 무엇이 있을까?
##############################################################
# 하나의 서버에 100만명의 사용자가 요청을 보내면 요청마다 쓰레드가 생성될텐데 이 문제를 어떻게 해결하는가?

# Node의 경우 싱글스레드 서버인데 100만명의 사용자가 요청을 보내면 어떻게 처리하는가?
##############################################################
# Node는 싱글 스레드인데, 그러면 cpu core를 1개만 사용한다. 어떻게 이를 보완하는가?

우선 대부분의 요청이 cpu 집약적이지 않은, io 집약적인 요청이라고 가정한다. 노드는 클러스터 모듈을 내장하고 있는데, 이는 cpu의 코어 개수만큼 자식 프로세스를 생성하고, 요청이 들어오면 마스터 프로세스에서 로드밸런싱으로 각각의 차일드 프로세스에게 일을 넘겨줄 수 있다. 클러스터 모듈을 사용하면 다른 장점도 있는데, 차일드 프로세스에 문제가 발생해도 다른 프로세스가 살아있고, 차일드 프로세스가 죽으면 다시 재생성하는 코드를 써두면 되기 때문에 장애애 대응하기 좋다는 점이다. 물론 제한점은 아래와 같다.
우선 메모리 공유가 되지 않는다. 프로세스끼리 메모리는 공유되지 않기 때문이다.  Now we would be forced to use some caching mechanism like Redis or Memcache and be able to access that from any process. 또한 스테이트풀한 api 호출은 작동하지 않는다. 왜냐하면 워커끼리의 커뮤니케이션이 보장되어 있지 않기 때문이다. 따라서 스테이트풀한 세션보다는 스테이트리스한 토큰등을 써서 인증 절차를 거치는 것이 좋다. pm2를 쓰면 이러한 것들을 쉽게 활용할 수 있다.


############################################################### 스프링에서 서버가 실행되면 Controller는 Spring Beans에 담겨있어 Client Thread의 요청이 들어오면 Controller객체를 새로 생성하지 않고 Spring Beans Container에서 꺼내써서 1개의 싱글톤 객체로 작동한다. 이 때, 다수의 사용자가 하나의 싱글톤 객체에 진입하려고 하면 어떤 문제가 발생하는가? 또한 어떻게 1개의 컨트롤러만으로 100만명의 요청을 다 처리할 수 있는가?

여러 클라이언트가 하나의 같은 객체 인스턴스를 공유하기 때문에 상태를 유지(stateful)하게 설계하면 안된다. 무상태(stateless)로 설계해야 한다! 특정 클라이언트에 의존적인 필드가 있으면 안된다
특정 클라이언트가 값을 변경할 수 있는 필드가 있으면 안된다!
공유 필드 대신에 자바에서 지역변수, 파라미터, ThreadLocal 등을 사용해야 한다.
##############################################################
# Node에 100만명의 사용자가 들어왔는데 그 중 단 하나의 작업이 cpu 계산이 매우 오래 걸리는 작업이다. 어떻게 해야 할까?

우선 반복문, 재귀함수등이 있다면 가능한 작은 범위로 쪼개야 한다. 
기본적으로 노드는 매우 많은 양의 io 집약적인 작업을 비동기적으로 처리하는데 특화되어 있는데, 이는 요청된 데이터가 매우 작을때까지 허용된다. 노드는 먼저 외부에서 받은 데이터를 메모리에 저장하고, json 데이터를 객체로 변환한 후에, 이 객체들로 연산을 수행한다. 또한 보낼때도 객체를 json으로 변환한 후에 클라이언트에게 보내도록 되어있다. 이 변환 연산이 많은 cpu를 소모하기 때문에 payload의 사이즈가 적은 것이 좋다. 또한 Promise.all로 너무 많은 양의 연산을 병렬처리하려고 하면 문제가 생긴다(왜?). 또한 메모리 누수가 있을 수 있는데, 이 경우 노드 내부의 가비지 콜렉터가 이 메모리를 해제하려고 반복적으로 연산을 수행하고 이는 cpu의 낭비를 만들 것이다.
##############################################################
# 공유 변수 문제를 해결할 수 있는 전략을 설명하라
##############################################################
# 데드락과 그 해결 방안을 설명하라
##############################################################

자기가 가지고 있는 쓰레드 풀에 있는 테스크 수보다 request가 많지가 않다면 동기로하나 비동기로하나 성능상에 별 차이가 없다. 이때는 코드 가독성이라던가 오버헤드를 줄이는 측면에서 비동기를 안 쓰는 게 낫다. 나중에 스케일이 커져서 로드가 몰리게 되면 갑자기 평탄하던 그래프가 치솟는다. 이때 비동기를 쓰면 완만하게 그래프가 올라간다. 즉 어느 정도 유지가 된다. 로드가 몰리면 모든 사람이 어느 정도는 느려질 수 있어도 한명이 엄청나게 오래 기다리다가 타임아웃되는 것을 방지하기 위해서는 비동기가 낫다.
동기식 입출력 (Synchronous I/O)
프로그램 I/O 요청을 했을 때 해당 I/O 작업이 완료되어야 다음 작업을 할 수 있는 방식이다.
I/O가 진행되는 동안 다음 명령을 수행하지 않고 기다린다.
I/O 상태의 프로세스는 blocked state로 전환된다.
I/O가 완료되면 인터럽트를 통해 완료를 알린다. 이후 CPU의 제어권이 기존 프로그램에게 넘어간다.
blocked state의 프로세스는 wait 상태로 돌아간다.
명령 수행 속도는 빠르지만 입출력 연산은 상대적으로 느리다. 기다리는 과정에서 자원 낭비를 초래한다.

보통 I/O가 진행되면 CPU는 다른 프로그램의 작업을 수행하게 된다.
여러 프로세스가 동시에 I/O 요청을 할 경우 각 요청을 큐에 넣어 순서대로 처리한다.

비동기식 입출력(Non-Synchronous I/O)
CPU의 제어권을 입출력 연산을 호출한 프로그램에게 곧바로 다시 부여한다.
I/O 결과와 관련 없는 연산이 있을 경우 주로 사용된다.
CPU는 I/O 결과와 상관 없이 처리 가능한 작업부터 처리한다.
I/O 연산이 완료되면 인터럽트를 통해 알린다.

Blocking I/O
직접 제어할 수 없는 대상의 작업(I/O)이 완료될 때까지 기다린다.
I/O가 완료되어야 제어권이 프로세스로 넘어간다.
동기와 마찬가지로 자원이 낭비된다.
Non-Blocking I/O
입출력 처리는 시작만 해둔 채 완료되지 않은 상태에서 다른 처리 작업을 계속 진행할 수 있도록 멈추지 않고 입출력 처리를 기다리는 방법을 말한다.
I/O 처리를 하는 전통적인 방법은 I/O 작업을 시작하면 완료될 때까지 기다리는 방법이다. 기존에는 synchronous I/O 혹은 blocking I/O를 통해 I/O 작업을 진행하는 동안 프로그램이 아무 일도 하지 않고 시간을 소비하게 만든다.
반면, Non-blocking I/O 방식을 사용하면 외부에 I/O 작업을 하도록 요청한 후, 즉시 다음 작업을 처리함으로써 시스템 자원을 더 효율적으로 사용할 수 있게된다.
그러나 I/O 작업이 완료된 이후에 처리해야 하는 후속 작업이 있다면, I/O 작업이 완료될 때까지 기다려야 한다. 따라서 이 후속 작업이 프로세스를 멈추지 않도록 만들기 위해 I/O 작업이 완료된 이후 후속 작업이 이어서 진행할 수 있도록 별도의 약속(Polling, Callback function 등)을 한다.

I/O 작업이 진행되는 동안에는 유저 프로세스의 작업을 중단시키지 않는다. 제어권을 바로 반납한다.
I/O 완료와 상관없이 작업 결과가 반환된다. 입력 데이터가 있을 때까지 반복하고, 입력 데이터가 있으면 결과가 전달된다.
대기하지 않아도 되지만 I/O 완료를 확인해야 하기 때문에 시스템 호출이 반복된다.
동기, 비동기는 개선된 I/O 이벤트 통지 모델이다.

정리

동기/비동기는 인터럽트 발생으로 인한 제어권 반한 시점에 중점을 두고 Blocking/Non-Blocking은 제어권 자체에 중점을 둔다는 점에서 차이가 있다
##############################################################
